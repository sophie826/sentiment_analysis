

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8k1iNXB47R6fdnWNa3XJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophie826/sentiment_analysis/blob/main/trustpilot_webscrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frNy9zHcuchQ"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "# Initialize lists\n",
        "review_titles = []\n",
        "review_dates_original = []\n",
        "review_dates = []\n",
        "review_ratings = []\n",
        "review_texts = []\n",
        "page_number = []\n",
        "\n",
        "# Set Trustpilot page numbers to scrape here\n",
        "from_page = 1\n",
        "to_page = 20\n",
        "\n",
        "for i in range(from_page, to_page + 1):\n",
        "    response = requests.get(f\"your url?page={i}\")\n",
        "    web_page = response.text\n",
        "    soup = BeautifulSoup(web_page, \"html.parser\")\n",
        "\n",
        "    for review in soup.find_all(class_ = \"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_reviewCard__hcAvl\"):\n",
        "        # Review titles\n",
        "        review_title = review.find(class_ = \"typography_heading-s__f7029 typography_appearance-default__AAY17\")\n",
        "        review_titles.append(review_title.getText())\n",
        "\n",
        "        # Review dates\n",
        "        review_date_original = review.select_one(selector=\"time\")\n",
        "        review_dates_original.append(review_date_original.getText())\n",
        "\n",
        "        # Convert review date texts into Python datetime objects\n",
        "        review_date = review.select_one(selector=\"time\").getText().replace(\"Updated \", \"\")\n",
        "        if \"minutes ago\" in review_date.lower() or \"hours ago\" in review_date.lower() or \"hour ago\" in review_date.lower():\n",
        "            review_date = dt.datetime.now().date()\n",
        "        elif \"a day ago\" in review_date.lower():\n",
        "            review_date = dt.datetime.now().date() - dt.timedelta(days=1)\n",
        "        elif \"days ago\" in review_date.lower():\n",
        "            review_date = dt.datetime.now().date() - dt.timedelta(days=int(review_date[0]))\n",
        "        else:\n",
        "            review_date = dt.datetime.strptime(review_date, \"%b %d, %Y\").date()\n",
        "        review_dates.append(review_date)\n",
        "\n",
        "        # Review ratings\n",
        "        review_rating = review.find(class_ = \"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\").findChild()\n",
        "        review_ratings.append(review_rating[\"alt\"])\n",
        "\n",
        "        # When there is no review text, append \"\" instead of skipping so that data remains in sequence with other review data e.g. review_title\n",
        "        review_text = review.find(class_ = \"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\")\n",
        "        if review_text == None:\n",
        "            review_texts.append(\"\")\n",
        "        else:\n",
        "            review_texts.append(review_text.getText())\n",
        "\n",
        "        # Trustpilot page number\n",
        "        page_number.append(i)\n",
        "\n",
        " #Create final dataframe from lists\n",
        "df_reviews = pd.DataFrame(list(zip(review_titles, review_dates_original, review_dates, review_ratings, review_texts, page_number)),\n",
        "                columns =['review_title', 'review_date_original', 'review_date', 'review_rating', 'review_text', 'page_number'])\n",
        "\n",
        "df_reviews.to_csv('edc_trustpilot.csv',index=None, header=True)\n",
        "\n"
      ]
    }
  ]
}
